{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os.path import join\n",
    "from time import time\n",
    "\n",
    "# !pip3 install git+https://github.com/iitzco/faced.git\n",
    "from faced import FaceDetector\n",
    "# download repository https://github.com/TropComplique/mtcnn-pytorch\n",
    "from mtcnn.src import detect_faces\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascades_path = '/home/egor/venvs/face_recognition/lib/python3.6/site-packages/cv2/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haarcascade_eye_tree_eyeglasses.xml\r\n",
      "haarcascade_eye.xml\r\n",
      "haarcascade_frontalcatface_extended.xml\r\n",
      "haarcascade_frontalcatface.xml\r\n",
      "haarcascade_frontalface_alt2.xml\r\n",
      "haarcascade_frontalface_alt_tree.xml\r\n",
      "haarcascade_frontalface_alt.xml\r\n",
      "haarcascade_frontalface_default.xml\r\n",
      "haarcascade_fullbody.xml\r\n",
      "haarcascade_lefteye_2splits.xml\r\n",
      "haarcascade_licence_plate_rus_16stages.xml\r\n",
      "haarcascade_lowerbody.xml\r\n",
      "haarcascade_profileface.xml\r\n",
      "haarcascade_righteye_2splits.xml\r\n",
      "haarcascade_russian_plate_number.xml\r\n",
      "haarcascade_smile.xml\r\n",
      "haarcascade_upperbody.xml\r\n",
      "__init__.py\r\n",
      "__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "!ls $cascades_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(join(cascades_path, 'haarcascade_frontalface_alt.xml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining webcam\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "fps = 0\n",
    "while(True):\n",
    "    # getting image from webcam\n",
    "    ret, img = cap.read()\n",
    "    # converting rbg image from webcam to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    t0 = time()\n",
    "    # detectMultiScale needs gray image\n",
    "    faces = face_cascade.detectMultiScale(gray_img)\n",
    "    # time of detection\n",
    "    dt = time() - t0\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    fps = 1. / dt\n",
    "    cv2.putText(img, 'FPS {:.4f}'.format(fps), (10, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0))\n",
    "    cv2.imshow('frame',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of detection. Average fps were 20."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![detection with haar cascades](images/haar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://github.com/iitzco/faced) to library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faced_detector = FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "fps = 0\n",
    "while(True):\n",
    "    # getting image from webcam\n",
    "    ret, img = cap.read()\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    t0 = time()\n",
    "    boxes = faced_detector.predict(rgb_img)\n",
    "    # time of detection\n",
    "    dt = time() - t0\n",
    "    \n",
    "    # gives x, y of center of face\n",
    "    for x, y, w, h, _ in boxes:\n",
    "        x0, y0 = int(x - w/2), int(y - h/2)\n",
    "        cv2.rectangle(img,(x0,y0),(x0 + w, y0 + h),(255,0,0),2)\n",
    "    \n",
    "    fps = 1. / dt\n",
    "    cv2.putText(img, 'FPS {:.4f}'.format(fps), (10, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0))\n",
    "    cv2.imshow('frame',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of detection with [faced](https://github.com/iitzco/faced) model. Average fps is 22. This is even higher than with cv2. It also has more robust detections."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![detection with faced model](images/faced_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[link](https://github.com/TropComplique/mtcnn-pytorch) to used library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "fps = 0\n",
    "while(True):\n",
    "    # getting image from webcam\n",
    "    ret, img = cap.read()\n",
    "#     pil_img = Image.fromarray(img).convert('RGB')\n",
    "    rgb_img = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
    "    pil_img = Image.fromarray(rgb_img)\n",
    "    \n",
    "    t0 = time()\n",
    "    try:\n",
    "        bounding_boxes, landmarks = detect_faces(pil_img)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # time of detection\n",
    "    dt = time() - t0\n",
    "    \n",
    "    # gives x, y of center of face\n",
    "    for x0, y0, x1, y1, _ in bounding_boxes:\n",
    "        x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "        cv2.rectangle(img,(x0, y0),(x1, y1),(255,0,0),2)\n",
    "    \n",
    "    fps = 1. / dt\n",
    "    cv2.putText(img, 'FPS {:.4f}'.format(fps), (10, 50), cv2.FONT_HERSHEY_PLAIN, 3, (0,255,0))\n",
    "    cv2.imshow('frame',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of detection with [MTCNN](https://arxiv.org/abs/1604.02878) model. The best detection quality but the slowest speed. Average FPS is about 6."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![detections with mtcnn model](images/mtcnn_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
